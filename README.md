# Pgp-Inhibitor-Prediction

### P-gp Interaction Profiling and SAR Analysis using LLMs and Explainable GNNs

📖 **Abstract**

Multidrug Resistance (MDR) remains a significant challenge in cancer chemotherapy, with the efflux pump P-glycoprotein (P-gp) playing a central role. This project introduces a novel, end-to-end computational pipeline to accelerate the discovery of P-gp modulators. We leverage Large Language Models (LLMs) to automatically curate a high-quality interaction dataset from biomedical literature. A dual-model system based on Graph Isomorphism Networks (GINE) was developed to profile compounds simultaneously as inhibitors and substrates, providing a nuanced pharmacological perspective. Rigorous external validation against the ChEMBL database revealed a significant "Domain Shift" between literature-based knowledge and assay-based data, a key finding that was confirmed with a control experiment (AUC 0.38 vs. 0.96). Finally, by employing Explainable AI (XAI) through GNNExplainer, our pipeline successfully reproduced established Structure-Activity Relationship (SAR) rules, demonstrating its validity as a powerful tool for hypothesis generation in drug discovery.

-----

🚀 **Key Features**

  * **LLM-Powered Data Curation**: A custom pipeline that uses the ChatGPT API to automatically extract and label P-gp-compound interactions from the latest PubMed abstracts, creating a dynamic and up-to-date dataset.
  * **Dual-Model System**: Two independent GINE models were developed to profile compounds from two pharmacological perspectives: **inhibition** and **substrateness**.
  * **P-gp Interaction Profile Map**: A novel 2D visualization method to intuitively classify compounds into four meaningful groups: **Specific Inhibitors**, **Specific Substrates**, **Dual-Role**, and **Non-Interactors**.
  * **Domain Shift Investigation**: Experimentally demonstrated and quantified the "Domain Shift" between literature-based knowledge and assay-based (ChEMBL) data, clarifying the model's applicability domain.
  * **XAI-driven SAR Hypothesis**: Used GNNExplainer to interpret the model's predictions and successfully reproduced known SAR rules for P-gp inhibitors and substrates from scratch.

-----

🔬 **Methodology & Pipeline**

The research was conducted following a systematic pipeline:

1.  **Data Curation & Labeling**:
      * PubMed abstracts related to P-gp were retrieved.
      * A prompted ChatGPT API batch job was used to perform structured extraction of compound-interaction pairs.
      * Compound names were standardized against PubChem and ChEMBL to obtain SMILES and InChIKeys, followed by a confidence-based labeling strategy.
2.  **Model Development**:
      * The problem was framed as two separate binary classification tasks (Inhibitor vs. Non-Inhibitor; Substrate vs. Non-Substrate).
      * Graph Isomorphism Network (GINE) was selected as the model architecture.
      * Hyperparameters were optimized for each model using Optuna with 5-fold cross-validation.
3.  **Analysis & Validation**:
      * Out-of-Fold (OOF) predictions were used to generate a reliable `final_results` dataframe for the Profile Map.
      * External validation was performed using a filtered dataset from the ChEMBL database.
      * A control experiment (training and testing exclusively on ChEMBL data) was conducted to diagnose the cause of the initial validation failure.
      * GNNExplainer was applied to the literature-trained models to analyze the top 15 most confident predictions for inhibitors and substrates.

-----

📂 **Repository Structure**

```
Pgp-Inhibitor-Prediction/
├── README.md                 # Project description file
├── requirements.txt          # List of required Python libraries
│
├── scripts/                  # Finalized Python execution scripts for reproducibility
│   ├── 01_fetch_pmids.py
│   ├── 02_run_batch_api.py
│   ├── 03_analyze_results.py
│   ├── 04_build_dataset.py
│   └── 05_train_and_evaluate.py
│
├── data/                     # Data files generated by scripts (not included in GitHub)
│   └── processed/
│       ├── pgp_dataset_for_inhibitor_model_v2.csv
│       └── ...
│
├── notebooks/                # Jupyter notebooks for experiments and analysis
│   ├── exploratory_analysis.ipynb
│   └── final_model_report.ipynb
│
└── results/                  # Final outputs (images, logs, etc.)
    └── figures/
        └── interaction_map.png
```

-----

📈 **Key Results & Findings**

#### 1\. P-gp Interaction Profile Map

Our dual-model system allowed for the creation of a pharmacological map, plotting the predicted probability of inhibition against the probability of being a substrate. This provides an at-a-glance profile for any given compound.

`[Insert P-gp Interaction Profile Map image here]`

#### 2\. Experimental Proof of Domain Shift

Our literature-trained model performed poorly on an external ChEMBL dataset (AUC ≈ 0.38). However, a control model trained and tested exclusively on ChEMBL data achieved excellent performance (AUC ≈ 0.96). This key finding proves that the performance gap was due to a fundamental difference in the data domains.

`[Insert Chemical Space Distribution plot image here]`

#### 3\. XAI-based SAR Hypothesis

Our pipeline successfully rediscovered the core SAR principles for P-gp interactions without prior knowledge.

  * **Key Features of Inhibitors**: High Hydrophobicity & Rigidity, Multiple Aromatic Anchors, Bulky Structures.
  * **Key Features of Substrates**: Cationic Properties, Structural Flexibility.

-----

🛠️ **Installation & Usage**

To run this project, first clone the repository and then install the required packages.

```bash
# 1. Clone the repository
git clone https://github.com/jay99sohn/Pgp-Inhibitor-Prediction.git

# 2. Navigate to the project directory
cd Pgp-Inhibitor-Prediction

# 3. Install required packages
pip install -r requirements.txt
```

#### **Pipeline Execution**

To reproduce the entire pipeline from data collection to model training, run the scripts in the `scripts/` folder in sequential order.

```bash
# Step 1: Collect abstracts from PubMed and create the API input file
python scripts/01_fetch_pmids.py

# Step 2: Run the OpenAI Batch API job and download the results
python scripts/02_run_batch_api.py

# Step 3: Parse the API results and extract a clean list of substance names
python scripts/03_analyze_results.py

# Step 4: Convert substance names to SMILES and build the final labeled CSV dataset
python scripts/04_build_dataset.py

# Step 5: Define the GINE model and run hyperparameter tuning with Optuna
python scripts/05_train_and_evaluate.py
```
